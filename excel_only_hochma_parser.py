import requests
from bs4 import BeautifulSoup
import re
import pandas as pd
import json
import time
from datetime import datetime
import os

class ExcelOnlyHochmaParser:
    def __init__(self):
        self.base_url = "https://nocr.net/com_kor_hochma"
        self.session = requests.Session()
        self.session.headers.update({
            'User-Agent': 'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36'
        })
        
        # í†µê³„ ë³€ìˆ˜
        self.total_processed = 0
        self.successful_parses = 0
        self.failed_parses = 0
        self.total_verses = 0
    
    def load_article_list(self, json_file):
        """ì¶”ì¶œëœ ê²Œì‹œê¸€ ëª©ë¡ ë¡œë“œ"""
        print(f"ğŸ“ ê²Œì‹œê¸€ ëª©ë¡ ë¡œë“œ ì¤‘: {json_file}")
        
        with open(json_file, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        articles = data['links']
        print(f"  ì´ ê²Œì‹œê¸€ ìˆ˜: {len(articles)}ê°œ")
        
        return articles
    
    def parse_single_article(self, article_id):
        """ë‹¨ì¼ ê²Œì‹œê¸€ íŒŒì‹±"""
        url = f"{self.base_url}/{article_id}"
        
        try:
            response = self.session.get(url, timeout=15)
            response.encoding = 'utf-8'
            
            if response.status_code != 200:
                return None, f"HTTP {response.status_code}"
            
            soup = BeautifulSoup(response.text, 'html.parser')
            
            # ì œëª© ì¶”ì¶œ
            title = self.extract_title(soup)
            if not title:
                return None, "ì œëª© ì¶”ì¶œ ì‹¤íŒ¨"
            
            # ì œëª©ì—ì„œ ì„±ê²½ì±…ëª…ê³¼ ì¥ ì¶”ì¶œ
            book_info = self.extract_book_info(title)
            if not book_info:
                return None, "ì„±ê²½ì±… ì •ë³´ ì¶”ì¶œ ì‹¤íŒ¨"
            
            # ë³¸ë¬¸ ì¶”ì¶œ
            content = self.extract_content(soup)
            if not content:
                return None, "ë³¸ë¬¸ ì¶”ì¶œ ì‹¤íŒ¨"
            
            # ì ˆë³„ë¡œ íŒŒì‹±
            verses = self.parse_verses(content, book_info['book_name'], book_info['chapter'])
            
            if not verses:
                return None, "ì ˆ íŒŒì‹± ì‹¤íŒ¨"
            
            return {
                'title': title,
                'book_name': book_info['book_name'],
                'chapter': book_info['chapter'],
                'verses': verses,
                'url': url
            }, None
            
        except Exception as e:
            return None, str(e)
    
    def extract_title(self, soup):
        """ì œëª© ì¶”ì¶œ"""
        # H1 íƒœê·¸ì—ì„œ ì œëª© ì°¾ê¸°
        h1_tags = soup.find_all('h1')
        for h1 in h1_tags:
            text = h1.get_text(strip=True)
            if 'í˜¸í¬ë§ˆ ì£¼ì„' in text:
                return text
        
        # title íƒœê·¸ì—ì„œ ì œëª© ì°¾ê¸°
        title_tag = soup.find('title')
        if title_tag:
            text = title_tag.get_text(strip=True)
            if 'í˜¸í¬ë§ˆ ì£¼ì„' in text:
                return text
        
        return None
    
    def extract_book_info(self, title):
        """ì œëª©ì—ì„œ ì„±ê²½ì±…ëª…ê³¼ ì¥ ì¶”ì¶œ"""
        pattern = r'í˜¸í¬ë§ˆ ì£¼ì„[,\s]*([ê°€-í£]+(?:ìƒ|í•˜)?(?:ì „ì„œ|í›„ì„œ)?(?:ì¼ì„œ|ì´ì„œ|ì‚¼ì„œ)?(?:ë³µìŒ)?(?:ê¸°)?(?:ì• ê°€)?)\s*(\d+)ì¥'
        match = re.search(pattern, title)
        
        if match:
            return {
                'book_name': match.group(1),
                'chapter': int(match.group(2))
            }
        
        return None
    
    def extract_content(self, soup):
        """ë³¸ë¬¸ ì¶”ì¶œ"""
        # ë‹¤ì–‘í•œ ë³¸ë¬¸ ì„ íƒì ì‹œë„
        selectors = [
            '.rhymix_content',
            '.xe_content', 
            '.rd_body',
            '#article_content',
            '.document_content'
        ]
        
        for selector in selectors:
            content_div = soup.select_one(selector)
            if content_div:
                # <br> íƒœê·¸ë¥¼ ì¤„ë°”ê¿ˆìœ¼ë¡œ ë³€í™˜
                for br in content_div.find_all('br'):
                    br.replace_with('\n')
                
                text = content_div.get_text()
                if text.strip():
                    return text
        
        return None
    
    def parse_verses(self, content, book_name, chapter):
        """ë³¸ë¬¸ì„ ì ˆë³„ë¡œ íŒŒì‹±"""
        verses = []
        
        # íŒ¨í„´ 1: ====31:1 (4ê°œ ë“±í˜¸) ë˜ëŠ” ===31:1 (3ê°œ ë“±í˜¸)
        equals_pattern = r'={3,}(\d+):(\d+)'
        equals_matches = list(re.finditer(equals_pattern, content))
        
        if equals_matches:
            # ë“±í˜¸ íŒ¨í„´ìœ¼ë¡œ ì ˆ êµ¬ë¶„
            for i, match in enumerate(equals_matches):
                verse_num = int(match.group(2))
                start_pos = match.end()
                
                if i < len(equals_matches) - 1:
                    end_pos = equals_matches[i + 1].start()
                    verse_content = content[start_pos:end_pos].strip()
                else:
                    verse_content = content[start_pos:].strip()
                
                if verse_content:
                    verses.append({
                        'verse': verse_num,
                        'content': verse_content
                    })
        else:
            # íŒ¨í„´ 2: ì¤„ë°”ê¿ˆ ê¸°ë°˜ ì ˆ êµ¬ë¶„
            lines = content.split('\n')
            current_verse = None
            current_content = []
            
            verse_pattern = r'^(\d+):(\d+(?:,\d+)*(?:-\d+)*)$'
            
            for line in lines:
                line = line.strip()
                if not line:
                    continue
                
                match = re.match(verse_pattern, line)
                if match:
                    # ì´ì „ ì ˆ ì €ì¥
                    if current_verse and current_content:
                        content_text = '\n'.join(current_content).strip()
                        if content_text:
                            # ì½¤ë§ˆë‚˜ í•˜ì´í”ˆìœ¼ë¡œ êµ¬ë¶„ëœ ì ˆ ì²˜ë¦¬
                            verse_nums = self.parse_verse_range(current_verse)
                            for verse_num in verse_nums:
                                verses.append({
                                    'verse': verse_num,
                                    'content': content_text
                                })
                    
                    # ìƒˆ ì ˆ ì‹œì‘
                    current_verse = match.group(2)
                    current_content = []
                else:
                    if current_verse:
                        current_content.append(line)
            
            # ë§ˆì§€ë§‰ ì ˆ ì €ì¥
            if current_verse and current_content:
                content_text = '\n'.join(current_content).strip()
                if content_text:
                    verse_nums = self.parse_verse_range(current_verse)
                    for verse_num in verse_nums:
                        verses.append({
                            'verse': verse_num,
                            'content': content_text
                        })
        
        return verses
    
    def parse_verse_range(self, verse_str):
        """ì ˆ ë²”ìœ„ íŒŒì‹± (ì˜ˆ: "37,38" ë˜ëŠ” "33-35")"""
        verse_nums = []
        
        if ',' in verse_str:
            # ì½¤ë§ˆë¡œ êµ¬ë¶„ëœ ì ˆë“¤
            for v in verse_str.split(','):
                try:
                    verse_nums.append(int(v.strip()))
                except ValueError:
                    continue
        elif '-' in verse_str:
            # í•˜ì´í”ˆìœ¼ë¡œ êµ¬ë¶„ëœ ë²”ìœ„
            parts = verse_str.split('-')
            if len(parts) == 2:
                try:
                    start = int(parts[0].strip())
                    end = int(parts[1].strip())
                    verse_nums.extend(range(start, end + 1))
                except ValueError:
                    pass
        else:
            # ë‹¨ì¼ ì ˆ
            try:
                verse_nums.append(int(verse_str.strip()))
            except ValueError:
                pass
        
        return verse_nums
    
    def save_to_excel(self, articles, output_file):
        """ê²°ê³¼ë¥¼ ì—‘ì…€ë¡œ ì €ì¥"""
        print(f"ğŸ“Š ì—‘ì…€ íŒŒì¼ ìƒì„± ì¤‘: {output_file}")
        
        all_data = []
        summary_data = []
        book_stats = {}
        
        for article in articles:
            if article['status'] == 'success' and article['parsed_data']:
                parsed = article['parsed_data']
                book_name = parsed['book_name']
                chapter = parsed['chapter']
                
                # ì„±ê²½ì±…ë³„ í†µê³„ ì—…ë°ì´íŠ¸
                if book_name not in book_stats:
                    book_stats[book_name] = {
                        'chapters': set(),
                        'total_verses': 0,
                        'total_content_length': 0
                    }
                
                book_stats[book_name]['chapters'].add(chapter)
                
                for verse in parsed['verses']:
                    all_data.append({
                        'article_id': article['article_id'],
                        'title': article['title'],
                        'book_name': book_name,
                        'chapter': chapter,
                        'verse': verse['verse'],
                        'content': verse['content'],
                        'content_length': len(verse['content']),
                        'url': parsed['url']
                    })
                    
                    book_stats[book_name]['total_verses'] += 1
                    book_stats[book_name]['total_content_length'] += len(verse['content'])
                
                summary_data.append({
                    'article_id': article['article_id'],
                    'title': article['title'],
                    'book_name': book_name,
                    'chapter': chapter,
                    'total_verses': len(parsed['verses']),
                    'avg_content_length': sum(len(v['content']) for v in parsed['verses']) / len(parsed['verses']),
                    'total_content_length': sum(len(v['content']) for v in parsed['verses']),
                    'status': 'success'
                })
            else:
                summary_data.append({
                    'article_id': article['article_id'],
                    'title': article['title'],
                    'book_name': '',
                    'chapter': 0,
                    'total_verses': 0,
                    'avg_content_length': 0,
                    'total_content_length': 0,
                    'status': article['error']
                })
        
        # ì„±ê²½ì±…ë³„ í†µê³„ ì •ë¦¬
        book_summary = []
        for book_name, stats in book_stats.items():
            book_summary.append({
                'book_name': book_name,
                'chapters_count': len(stats['chapters']),
                'chapters_list': ', '.join(map(str, sorted(stats['chapters']))),
                'total_verses': stats['total_verses'],
                'avg_verse_length': stats['total_content_length'] / max(stats['total_verses'], 1),
                'total_content_length': stats['total_content_length']
            })
        
        # ì—‘ì…€ íŒŒì¼ ìƒì„±
        with pd.ExcelWriter(output_file, engine='openpyxl') as writer:
            # 1. ì „ì²´ ì£¼ì„ ë°ì´í„°
            if all_data:
                df_all = pd.DataFrame(all_data)
                df_all.to_excel(writer, sheet_name='ì „ì²´ì£¼ì„ë°ì´í„°', index=False)
            
            # 2. íŒŒì‹± ìš”ì•½
            df_summary = pd.DataFrame(summary_data)
            df_summary.to_excel(writer, sheet_name='íŒŒì‹±ìš”ì•½', index=False)
            
            # 3. ì„±ê²½ì±…ë³„ í†µê³„
            if book_summary:
                df_books = pd.DataFrame(book_summary)
                df_books = df_books.sort_values('book_name')
                df_books.to_excel(writer, sheet_name='ì„±ê²½ì±…ë³„í†µê³„', index=False)
            
            # 4. ì „ì²´ í†µê³„
            stats_data = {
                'í•­ëª©': [
                    'ì´ ê²Œì‹œê¸€ ìˆ˜', 
                    'ì„±ê³µì  íŒŒì‹±', 
                    'ì‹¤íŒ¨í•œ íŒŒì‹±', 
                    'ì„±ê³µë¥ (%)', 
                    'ì´ ì ˆ ìˆ˜', 
                    'í‰ê·  ì ˆ/ê²Œì‹œê¸€',
                    'ì„±ê²½ì±… ìˆ˜',
                    'ì´ ë‚´ìš© ê¸¸ì´'
                ],
                'ê°’': [
                    self.total_processed,
                    self.successful_parses,
                    self.failed_parses,
                    round((self.successful_parses / max(self.total_processed, 1)) * 100, 1),
                    self.total_verses,
                    round(self.total_verses / max(self.successful_parses, 1), 1),
                    len(book_stats),
                    sum(len(item['content']) for item in all_data) if all_data else 0
                ]
            }
            df_stats = pd.DataFrame(stats_data)
            df_stats.to_excel(writer, sheet_name='ì „ì²´í†µê³„', index=False)
        
        print(f"âœ… ì—‘ì…€ íŒŒì¼ ì €ì¥ ì™„ë£Œ: {output_file}")
        
        # ìš”ì•½ ì •ë³´ ì¶œë ¥
        print(f"\nğŸ“Š íŒŒì‹± ê²°ê³¼ ìš”ì•½:")
        print(f"  ğŸ“š ì„±ê²½ì±…: {len(book_stats)}ê¶Œ")
        print(f"  ğŸ“„ ì´ ì ˆ: {self.total_verses}ê°œ")
        print(f"  âœ… ì„±ê³µ: {self.successful_parses}ê°œ")
        print(f"  âŒ ì‹¤íŒ¨: {self.failed_parses}ê°œ")
        
        return output_file
    
    def bulk_parse(self, json_file, max_articles=None):
        """ëŒ€ëŸ‰ íŒŒì‹± ì‹¤í–‰ (ì—‘ì…€ë§Œ ì €ì¥)"""
        print("ğŸ“Š í˜¸í¬ë§ˆ ì£¼ì„ ì—‘ì…€ ì „ìš© íŒŒì‹± ì‹œì‘")
        print("=" * 60)
        
        # ê²Œì‹œê¸€ ëª©ë¡ ë¡œë“œ
        articles = self.load_article_list(json_file)
        
        # ê°œìˆ˜ ì œí•œ (í…ŒìŠ¤íŠ¸ìš©)
        if max_articles:
            articles = articles[:max_articles]
            print(f"âš ï¸ í…ŒìŠ¤íŠ¸ ëª¨ë“œ: ì²˜ìŒ {max_articles}ê°œë§Œ íŒŒì‹±")
        
        self.total_processed = len(articles)
        
        print(f"ğŸ“Š íŒŒì‹± ëŒ€ìƒ: {self.total_processed}ê°œ ê²Œì‹œê¸€")
        print("=" * 60)
        
        start_time = time.time()
        results = []
        
        for i, article in enumerate(articles, 1):
            article_id = article['article_id']
            title = article['title']
            
            print(f"ì§„í–‰: {i}/{self.total_processed} - ê²Œì‹œê¸€ {article_id}: ", end='')
            
            # íŒŒì‹± ì‹¤í–‰
            parsed_data, error = self.parse_single_article(article_id)
            
            if parsed_data:
                verse_count = len(parsed_data['verses'])
                print(f"{verse_count}ê°œ ì ˆ")
                
                results.append({
                    'article_id': article_id,
                    'title': title,
                    'status': 'success',
                    'parsed_data': parsed_data,
                    'verse_count': verse_count,
                    'error': None
                })
                
                self.successful_parses += 1
                self.total_verses += verse_count
            else:
                print(f"íŒŒì‹± ì‹¤íŒ¨ - {error}")
                results.append({
                    'article_id': article_id,
                    'title': title,
                    'status': 'failed',
                    'parsed_data': None,
                    'verse_count': 0,
                    'error': error
                })
                
                self.failed_parses += 1
            
            # ì§„í–‰ë¥  í‘œì‹œ
            if i % 50 == 0:
                elapsed = time.time() - start_time
                progress = (i / self.total_processed) * 100
                print(f"ì§„í–‰ë¥ : {progress:.1f}% ({i}/{self.total_processed}) - ê²½ê³¼ì‹œê°„: {elapsed:.1f}ì´ˆ")
            
            # ìš”ì²­ ê°„ê²© (ì„œë²„ ë¶€í•˜ ë°©ì§€)
            time.sleep(0.1)
        
        # ìµœì¢… ê²°ê³¼
        elapsed_time = time.time() - start_time
        print(f"\nğŸ‰ íŒŒì‹± ì™„ë£Œ!")
        print(f"  ì´ ì²˜ë¦¬ ì‹œê°„: {elapsed_time:.1f}ì´ˆ")
        print(f"  ì„±ê³µ: {self.successful_parses}ê°œ")
        print(f"  ì‹¤íŒ¨: {self.failed_parses}ê°œ")
        print(f"  ì´ ì ˆ ìˆ˜: {self.total_verses}ê°œ")
        print(f"  ì„±ê³µë¥ : {(self.successful_parses/self.total_processed)*100:.1f}%")
        
        # ì—‘ì…€ ì €ì¥
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        excel_file = f"complete_hochma_parsed_{timestamp}.xlsx"
        self.save_to_excel(results, excel_file)
        
        return results

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    print("ğŸ“– í˜¸í¬ë§ˆ ì£¼ì„ ì—‘ì…€ ì „ìš© íŒŒì‹± ì‹œìŠ¤í…œ")
    print("=" * 50)
    
    # JSON íŒŒì¼ í™•ì¸
    json_files = [f for f in os.listdir('.') if f.startswith('hochma_all_links_') and f.endswith('.json')]
    
    if not json_files:
        print("âŒ ê²Œì‹œê¸€ ëª©ë¡ JSON íŒŒì¼ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        print("   ë¨¼ì € extract_all_hochma_links.pyë¥¼ ì‹¤í–‰í•˜ì„¸ìš”.")
        return
    
    # ê°€ì¥ ìµœê·¼ íŒŒì¼ ì‚¬ìš©
    json_file = sorted(json_files)[-1]
    print(f"ğŸ“ ì‚¬ìš©í•  ê²Œì‹œê¸€ ëª©ë¡: {json_file}")
    
    # íŒŒì„œ ì´ˆê¸°í™”
    parser = ExcelOnlyHochmaParser()
    
    # ì‚¬ìš©ì ì„ íƒ
    print("\nğŸ¯ íŒŒì‹± ëª¨ë“œë¥¼ ì„ íƒí•˜ì„¸ìš”:")
    print("  1. ì „ì²´ íŒŒì‹± (1,190ê°œ ëª¨ë“  ê²Œì‹œê¸€)")
    print("  2. í…ŒìŠ¤íŠ¸ íŒŒì‹± (ì²˜ìŒ 50ê°œë§Œ)")
    print("  3. ì‚¬ìš©ì ì§€ì • ê°œìˆ˜")
    
    try:
        choice = input("ì„ íƒ (1/2/3): ").strip()
        
        if choice == '1':
            max_articles = None
        elif choice == '2':
            max_articles = 50
        elif choice == '3':
            max_articles = int(input("íŒŒì‹±í•  ê²Œì‹œê¸€ ìˆ˜: "))
        else:
            print("ì˜ëª»ëœ ì„ íƒì…ë‹ˆë‹¤. ì „ì²´ íŒŒì‹±ì„ ì§„í–‰í•©ë‹ˆë‹¤.")
            max_articles = None
    except (ValueError, KeyboardInterrupt):
        print("ì „ì²´ íŒŒì‹±ì„ ì§„í–‰í•©ë‹ˆë‹¤.")
        max_articles = None
    
    # ëŒ€ëŸ‰ íŒŒì‹± ì‹¤í–‰
    results = parser.bulk_parse(
        json_file=json_file,
        max_articles=max_articles
    )
    
    print(f"\nâœ… ëª¨ë“  ì‘ì—… ì™„ë£Œ!")

if __name__ == "__main__":
    main() 